%
% Copyright © 2016 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%
%{
%\label{chap:reciprocal}

The end goal of this chapter is to be able to integrate multivector functions along curves and surfaces, known collectively as manifolds.
For our purposes, a manifold is defined by a parameterization, such as the vector valued function \( \Bx(a,b) \) where \( a, b\) are scalar parameters.  With one parameter the vector traces out a curve, with two a surface, three a volume, and so forth.
The respective partial derivatives of such a parameterized vector define a local basis for the surface at the point at which the partials are evaluated.
The span of such a basis is called the tangent space, and the partials that constitute it are not necessarily orthonormal, or even orthogonal.

Unfortunately, in order to work with the curvilinear non-orthonormal bases that will be encountered in general integration theory, some
additional tools are required.

\begin{itemize}
\item
We introduce a reciprocal frame which partially generalizes the notion of orthogonality to non-orthonormal bases.
\item
We will borrow the upper and lower index (tensor) notation from relativistic physics that is useful for the intrinsically non-orthonormal spaces encountered in that study, as this notation works well to define the reciprocal frame.
\end{itemize}
\index{reciprocal frame}
\index{\(\Bx^i\)}
\index{\({\delta_i}^j\)}
\input{Definition_reciprocal_frame.tex}
With an orthogonal basis, every basis vector is orthogonal to every other vector, so any orthonormal basis is also its reciprocal basis.
In general, if the original basis is not-orthogonal, every reciprocal basis vector is orthogonal to all but one of the original basis vectors, but may not be orthogonal to any other reciprocal basis vector.

If the curvilinear basis vectors \( \setlr{ \Bx_i } \) are orthogonal, then the reciprocal vectors \( \Bx^i \) are easy to compute.  Since they must each satisfy \( \Bx^i \cdot \Bx_i = 1 \), let \( \Bx^i = \alpha \Bx_i \), then
\begin{equation}\label{eqn:reciprocal:401}
\begin{aligned}
1
&= \Bx^i \cdot \Bx_i \\
&= \lr{ \alpha \Bx_i } \cdot \Bx_i \\
&= \alpha \lr{ \Bx_i \cdot \Bx_i },
\end{aligned}
\end{equation}
or
\begin{equation}\label{eqn:reciprocal:402}
\Bx^i = \inv{ \Bx_i \cdot \Bx_i } \Bx_i = \inv{\Bx_i}.
\end{equation}
More general techniques for computation of reciprocal bases will be required for non-orthoganal bases.

Mixed index variables have been introduced for the first time in this text, which may be unfamiliar.  These are most often used in tensor algebra, where any expression that has pairs of upper and lower indexes implies a sum, and is called the summation (or Einstein) convention.  For example:
\begin{equation}\label{eqn:reciprocal:400}
\begin{aligned}
a_i b^i &\equiv \sum_i a_i b^i \\
{A^{i}}_j B_i C^j &\equiv \sum_{i,j} {A^{i}}_j B_i C^j.
\end{aligned}
\end{equation}

Summation convention will not be used explicitly in this text, as it deviates from normal practises in electrical engineering\footnote{Generally, when summation convention is used, explicit summation is only used explicitly when upper and lower indexes are not perfectly matched, but summation is still implied.  Readers of texts that use summation convention can check for proper matching of upper and lower indexes to ensure that the expressions make sense.  Such matching is the reason a mixed index Kronecker delta has been used in the definition of the reciprocal frame.}.

\subsubsection{Vector coordinates.}
The most important application of a reciprocal frame is for the computation of the coordinates of a vector with respect to a non-orthonormal frame.
Let a vector \( \Ba \) have coordinates \( a^i \) with respect to a basis \( \setlr{ \Bx_i } \)
\begin{equation}\label{eqn:reciprocal:20}
\Ba = \sum_j a^j \Bx_j,
\end{equation}
where \( j \) in \( a^j \) is an index not a power\footnote{In tensor algebra, any index that is found in matched upper and lower index pairs, is known as a dummy summation index, whereas an index that is unmatched is known as a free index.  For example, in \( a^j b_{ij} \) (summation implied) \( j \) is a summation index, and \( i \) is a free index.  We are free to make a change of variables of any summation index, so for the same example we can write
\( a^k b_{ik} \).  These index tracking conventions are obvious when summation symbols are included explicitly, as we will do.}.

Dotting with the reciprocal frame vectors \( \Bx^i \) provides these coordinates \( a^i \)
\begin{equation}\label{eqn:reciprocal:40}
\begin{aligned}
\Ba \cdot \Bx^i
&= \lr{\sum_j a^j \Bx_j} \cdot \Bx^i \\
&= \sum_j a^j {\delta_j}^i \\
&= a^i.
\end{aligned}
\end{equation}

Alternatively, coordinates can be computed with respect to the reciprocal frame.  Let those coordinates be \( a_i \), so that
\begin{equation}\label{eqn:reciprocal:60}
\Ba = \sum_i a_i \Bx^i.
\end{equation}

Dotting with the basis vectors \( \Bx_i \) provides the reciprocal frame relative coordinates \( a_i \)
\begin{equation}\label{eqn:reciprocal:80}
\begin{aligned}
\Ba \cdot \Bx_i
&= \lr{\sum_j a_j \Bx^j} \cdot \Bx_i \\
&= \sum_j a_j {\delta^j}_i \\
&= a_i.
\end{aligned}
\end{equation}

We can summarize \cref{eqn:reciprocal:40} and \cref{eqn:reciprocal:80} by stating that a vector can be expressed in terms of coordinates relative to either the original or reciprocal basis as follows
\begin{equation}\label{eqn:reciprocal:420}
\Ba
= \sum_j \lr{ \Ba \cdot \Bx^j } \Bx_j
= \sum_j \lr{ \Ba \cdot \Bx_j } \Bx^j.
\end{equation}

In tensor algebra the basis is generally implied\footnote{
In tensor algebra, a vector, identified by the coordinates \( a^i \) is called a contravariant vector.
When that vector is identified by the coordinates \( a_i \) it is called a covariant vector.  These labels relate to how the coordinates transform with respect to norm preserving transformations.
We have no need of this nomenclature, since we never transform coordinates in isolation, but will always transform the coordinates along with their associated basis vectors.}.

%When doing tensor algebra manipulations, you'll generally have the freedom to swap any pairs of upper and lower indexes as done above.

An example of a 2D oblique Euclidean basis and a corresponding reciprocal basis is plotted in \cref{fig:obliqueReciprocal:obliqueReciprocalFig2}.
Also plotted are the superposition of the projections required to arrive at point \( (4,2) \) along the \( \Be_1, \Be_2 \) directions or the \( \Be^1, \Be^2 \) directions.
In this plot, neither of the reciprocal frame vectors \( \Be^i \) are orthogonal to the corresponding basis vectors \( \Be_i \).
When one of \( \Be_i \) is increased(decreased) in magnitude, there will be a corresponding decrease(increase) in the magnitude of \( \Be^i \), but if the orientation is remained fixed, the corresponding direction of the reciprocal frame vector stays the same.

\mathImageFigure{../figures/GAelectrodynamics/obliqueReciprocalFig2}{Oblique and reciprocal bases.}{fig:obliqueReciprocal:obliqueReciprocalFig2}{0.5}{obliqueReciprocal.nb}

